---
title: "ISa 414 Final Project"
output: html_notebook
---

```{r}
#install necessary packages
install.packages("dplyr")
install.packages("dp")
install.packages("rgeos")
install.packages("sp")
install.packages("ggplot2")
install.packages("rgdal")
install.packages("maps")
install.packages ("XML")

#load library
library ("XML")
library(dplyr)
library(rgdal)
library(rgeos)
library(sp)
library(ggplot2)
library(maps)
```
newtaxi<-sampletaxi
```{r}
#create a function to scrap the CSV from the taxi website. Can use multiple 
# months
scrap_phone<- function(year){
  
  url<- "https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2016-11.csv"
  first<- substr(url, 1,59)
  second<- substr(url, 67, 70)
  combined<- paste(first, year, second, sep="")
  newtaxi<- read.csv(url(combined))
 return(newtaxi)
}
```

aggregate the taxi data
```{r}
# 
aggregating<- function(){
  newtaxi$tpep_pickup_datetime <- as.POSIXlt(round(as.double(sampletaxi$tpep_pickup_datetime)/+
                                                   (60*60))*(60*60),origin=(as.POSIXlt('2016-01-01')))

pos_first_space <- regexpr(pattern = " ", newtaxi$tpep_pickup_datetime)
pickup_date <- substr(newtaxi$tpep_pickup_datetime, 0, pos_first_space - 1)

pickup_hour <- substr(newtaxi$tpep_pickup_datetime, pos_first_space + 1, length(newtaxi$tpep_pickup_datetime))

pickup <- rbind(data.frame(pickup_date, pickup_hour, newtaxi$pickup_latitude, newtaxi$pickup_longitude))

colnames(pickup) <- c("Date", "Hour", "Latitude", "Longitude")

pickup <- pickup %>%
  filter(Latitude != 0.00000 & Longitude != 0.00000)

return(data.frame(pickup))
}
```


read in the shape file 
```{r}
scrap_neighborhood<- function(NY){

        wd<- setwd("M:/414 Carvalho")
        temporary<-tempfile()
        url<- "https://www.zillowstatic.com/static/shp/ZillowNeighborhoods-NY.zip"
        download.file(url, temporary)

        file<-unzip(temporary, "ZillowNeighborhoods-NY.shp")


        NY <- readOGR(dsn = "M:/414 Carvalho",
                 layer = "ZillowNeighborhoods-NY" )
        return(NY)
     
        }
```


function for the shape file after its read in 
```{r}
mix_data<- function(){
ny <- shape[shape$City == "New York",]
poi <- data.frame(lng =pickup$Longitude, 
                  lat =pickup$Latitude,
                  id  =c("A", "B"), stringsAsFactors=F)
dat <- poi
coordinates(dat) <- ~lng+lat

#Tell R that taxi coords are same as ny polygons
proj4string(dat) <- proj4string(ny)

dat$neighboorhood <- over(dat, ny)$Name
inside_ny <- !is.na(over(dat, as(ny, "SpatialPolygons")))
mean(inside_ny)


#Determine which neighborhood each poi is located in
dat$neighboorhood <- over(dat, ny)$Name
return(dat)
}
```

eventually make a function for the API
```{r}
fileUrl <- "http://api.wunderground.com/api/7b48d2bca2801a7c/history_20160101/q/NY/NYC.xml"

weather_list <- data.frame()


for (n in 1:12) {  
  if(n %% 2 != 0){
    ndays <- 31
  }
  else if(n == 2){
    ndays <- 28
  }
  else{
    ndays <- 30
  }
  
  if(n < 10){
    
    month <- paste(0,n, sep = "")
  }
  else{
    month <- n
  }
  
  
  for (i in 1:ndays) {
    
    if(i < 10){
      day <- paste(0,i, sep = "")
    }
    else{
      day <- i
    }
    
    #creates URL for API
    url <- paste("http://api.wunderground.com/api/7b48d2bca2801a7c/history_2016", month, day, "/q/NY/NYC.json", sep = "")
    
    #sets df as JSON data from API
    df <- fromJSON(url)
    
    
    json_df <- lapply(df$history, function(x) {
      x[sapply(x, is.null)] <- NA
      unlist(x)
    })
    
    day_sum <- as.data.frame(json_df$dailysummary, stringsAsFactors = FALSE)
    
    #appends data for each day to a previously made data frame
    weather_list <- append(weather_list, day_sum)
    
    Sys.sleep(5)
  }
}

weather_df <- as.data.frame(weather_list, row.names = row.names(day_sum))

weather_df <- as.data.frame(t(weather_df))

date_col <- ymd(paste(weather_df$date.year, weather_df$date.mon, weather_df$date.mday, sep = "-"))

weather_df <- cbind.data.frame(date_col, weather_df)

row.names(weather_df) <- NULL

daily_weather <- weather_df %>%
  select(date_col, snow, fog, rain, meantempi, precipi, thunder)
```

```{r}
scrap_phone("2016-01")
pickup<-aggregating()
shape<- scrap_neighborhood(NY)
dat<-mix_data()
```

